{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Example of WSIDataloader class usage\n",
    "\n",
    "This notebook presents how to use the `WSIDataloader` class to efficiently load randomly selected patches from a list of WSIs using multiple CPU workers, and apply data augmentation to these patches using GPU acceleration.\n",
    "\n",
    "To define the `patch_generator` function, we chose to use the [`TIAToolbox`](https://github.com/TissueImageAnalytics/tiatoolbox) library, but any other similar implementation using ``openslide`` as a backend should work.\n",
    "\n",
    "This notebook was executed on a CentOS machine with 32GB of RAM, a Core i9 13900 and an RTX4090. We strongly recommend storing the WSIs on an SSD for fast random access."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below cell, we create two things:\n",
    "1. The `CustomSlidingWindowPatchExtractor` class: inherits from TIAToolbox's `SlidingWindowPatchExtractor`, only adding a definition for the `__len__(self)` method, to use it as an iterator.\n",
    "\n",
    "2. The `get_patches(wsi_path)` function: This functions takes the path to a WSI as input and outputs an iterator over all the WSI patches as defined by the given parameters. The `mask` used here is the simplest `TIAToolbox` Otsu mask implementation. The other parameters will make the iterator extract all non overlapping patches of size 224x224 at a 20x magnification objective.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from tiatoolbox.tools.patchextraction import SlidingWindowPatchExtractor\n",
    "from tiatoolbox.wsicore.wsireader import WSIReader\n",
    "import torchvision.transforms.v2 as transforms\n",
    "from torch.nn import Sequential\n",
    "from tqdm import tqdm\n",
    "\n",
    "from wsiloader import WSIDataloader\n",
    "\n",
    "\n",
    "class CustiomSlidingWindowPatchExtractor(SlidingWindowPatchExtractor):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.locations_df.shape[0] if self.locations_df is not None else 0\n",
    "\n",
    "\n",
    "def get_patches(wsi_path: str):\n",
    "    wsi = WSIReader.open(input_img=wsi_path)\n",
    "\n",
    "    # This mask can and should be adaptated to your data\n",
    "    # Here we use a simple Otsu\n",
    "    mask = wsi.tissue_mask(resolution=1.25, units=\"power\")\n",
    "\n",
    "    # All of these parameters can and should be adapted to your specific needs\n",
    "    patch_size = 224  # Square patch of size 224x224\n",
    "    resolution = 20   # 20x magnification objective\n",
    "    overlap    = 0.0  # No overlap between extracted patches\n",
    "\n",
    "    patches = CustiomSlidingWindowPatchExtractor(\n",
    "        input_img=wsi,\n",
    "        patch_size=(patch_size,)*2,\n",
    "        stride=(patch_size - int(overlap*patch_size),)*2,\n",
    "        resolution=resolution,\n",
    "        units=\"power\",\n",
    "        input_mask=mask,\n",
    "        min_mask_ratio=0.3,\n",
    "        within_bound=True,\n",
    "    )\n",
    "\n",
    "    return patches\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below we create a `WSIDataloader` instance. For this example we used a subset of 27 WSIs (39GB total) from the normal train set of the [Camelyon16](https://camelyon16.grand-challenge.org/Data/) dataset. We also define a set of strong augmentations typically seen in various contrastive learning frameworks. Note that instead of the usual `transforms.Compose` we use `torch.nn.Sequential` to enable the tranforms execution on the available cuda device. The `WSIDataloader` class will then load the data using multiple `torch.utils.data.Dataloader` CPU workers and will then apply the transforms on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building WSI index:   0%|                                                                        | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building WSI index: 100%|█████████████████████████████| 26/26 [00:26<00:00,  1.00s/it, [8612 > 146,414 indexed patches]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches: 1143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# List WSI samples from the normal train set of the Camelyon16 dataset\n",
    "wsi_paths = list(Path(\"/data/camelyon_samples\").glob(\"*.tif\"))\n",
    "\n",
    "augmentations = Sequential(\n",
    "    transforms.RandomResizedCrop(224, scale=(0.2, 1.), antialias=True),\n",
    "    transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.RandomApply([transforms.GaussianBlur(3, [.1, 2.])], p=0.5),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.Normalize(mean=[0.6684, 0.5115, 0.6791],\n",
    "                         std=[0.2521, 0.2875, 0.2100])\n",
    ")\n",
    "augmentations.to(\"cuda\")\n",
    "\n",
    "# Pytorch Dataloader Parameters:\n",
    "dataloader_params = dict(\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "loader = WSIDataloader(\n",
    "    wsi_paths=wsi_paths,\n",
    "    patch_generator=get_patches,\n",
    "    transforms=augmentations,\n",
    "    transforms_device=\"cuda\",\n",
    "    **dataloader_params,\n",
    ")\n",
    "print(f\"Number of batches: {len(loader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now iterate through the loader the same way as when using a `torch.utils.data.Dataloader`, but for every batch, patches will be randomly sampled across all WSIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1143/1143 [02:23<00:00,  7.98it/s]\n"
     ]
    }
   ],
   "source": [
    "for batch in tqdm(loader):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell demonstrates the efficiency of sequentially applying the tranforms on GPU instead of applying them on CPU in the Dataloader workers. When the `transforms_device` parameter is set to `cpu`, transforms are passed down to the dataset and applied in parallel using the default Dataloader workers behaviour. In this simple example we see a substantial time improvement when using GPU for transforms execution (2:23 vs 3:35)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building WSI index: 100%|█████████████████████████████| 26/26 [00:26<00:00,  1.00s/it, [8612 > 146,414 indexed patches]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches: 1143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1143/1143 [03:35<00:00,  5.31it/s]\n"
     ]
    }
   ],
   "source": [
    "loader = WSIDataloader(\n",
    "    wsi_paths=wsi_paths,\n",
    "    patch_generator=get_patches,\n",
    "    transforms=augmentations.to(\"cpu\"),\n",
    "    transforms_device=\"cpu\",\n",
    "    **dataloader_params,\n",
    ")\n",
    "print(f\"Number of batches: {len(loader)}\")\n",
    "\n",
    "for batch in tqdm(loader):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "placenta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
